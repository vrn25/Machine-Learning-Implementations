{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJZEAvwSFAcA"
   },
   "source": [
    "# **Sonic, the Hedgehog - Using Q learning**\n",
    "\n",
    "## A simple platform game to make Sonic reach the Goal using **Reinforcement Learning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thpINIv_Jkz3"
   },
   "source": [
    "## **States**:\n",
    "   * Start state S<br>\n",
    "   * Goal state G (and only terminal state)<br>\n",
    "   * Obstacle_1<br>\n",
    "   * Obstacle_2<br>\n",
    "   * Rest all states\n",
    "   \n",
    "## **Actions**:\n",
    "   * Move Straight<br>\n",
    "   * Low Jump<br>\n",
    "   * High Jump<br>\n",
    "   * Slide<br>\n",
    "   \n",
    "## **Game Description**:\n",
    "The aim of the agent (Sonic) is to find an optimal policy to reach the Goal state from Start state, avoiding the obstacles in the way and maximizing the net reward. Sonic is allowed to move only in the forward straight direction. The obstacles on the way can be avoided by jumping (Obstacle_1) or sliding (Obstacle_2). Reward can also be gained in certain cases if the height of the jump is chosen appropriately (higher jump is made).<br>\n",
    "\n",
    "### **Defining Reward**:\n",
    "\n",
    "* When agent needs to jump -> **-0.05** reward on jumping, and game continues, **-1** reward on moving forward or on sliding, and game ends. An additional reward of **+0.02** is given if jump is of appropriate height in certain cases.\n",
    "\n",
    "* When agent needs to slide -> **-0.05** reward on sliding, and game continues, **-1** reward on moving forward or jumping to any height, and game ends.\n",
    "\n",
    "* When agent needs to move straight - > **-0.05** reward on going straight, and game continues, **-0.2** reward on either jumping to any height or sliding (to make sure that it does not jump or slide unnecessarily) and game continues\n",
    "\n",
    "* When agent reachs goal state -> Reward of **+1** is given and game ends.\n",
    "\n",
    "### **Example**:\n",
    "If obstacle_1 is there between cell 2 and 4, then the agent needs to jump from cell 2 to cell 4. It also needs to check if extra reward is obtained on jumping higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbzYL91aZyh7"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLC97HRBEtki"
   },
   "outputs": [],
   "source": [
    "def env(state,action):\n",
    "  obstacle_1 = [[0,1,1],[3,7,14]]\n",
    "  obstacle_2 = [11,17]\n",
    "  \n",
    "  # when agent needs to jump\n",
    "  if((state+1) in obstacle_1[1]):\n",
    "    if(action==1 or action==2):    \n",
    "      if(obstacle_1[0][obstacle_1[1].index(state+1)] and action==2):\n",
    "        return -0.03,state+2,0\n",
    "      else:\n",
    "        return -0.05,state+1,0\n",
    "    else:\n",
    "      return -1,state+1,1\n",
    "    \n",
    "  # when agent needs to slides\n",
    "  elif((state+1) in obstacle_2):\n",
    "    if(action==3):\n",
    "      return -0.05,state+2,0\n",
    "    else:\n",
    "      return -1,state+1,1\n",
    "  \n",
    "  # when goal achieved\n",
    "  elif(state==19 and action==0):\n",
    "    return 1,state+1,1\n",
    "  \n",
    "  # in all other cases\n",
    "  else:\n",
    "    if(action==0):\n",
    "      return -0.05,state+1,0\n",
    "    else:\n",
    "      return -0.2,state+1,0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bovTIKAvWl7o"
   },
   "outputs": [],
   "source": [
    "def qlearning():\n",
    "  alpha = 0.1\n",
    "  discount = 0.9\n",
    "  epsilon = 0.2\n",
    "  num_actions = 4\n",
    "  cells = 21\n",
    "  episodes = 100000\n",
    "  \n",
    "  Q = [[] for i in range(cells)]\n",
    "  print('Q values before game-play: ')\n",
    "  print('            STRAIGHT   LOW JUMP   HIGH JUMP   SLIDE')\n",
    "  \n",
    "  for i in range(cells):\n",
    "    if(i==cells-1):\n",
    "      Q[i][:] = [0,0,0,0]\n",
    "    else:\n",
    "      Q[i] = [random.uniform(0,1) for j in range(num_actions)]\n",
    "      \n",
    "  for i in range(cells):\n",
    "    print('state %d:      %s' %(i,Q[i]))\n",
    "  \n",
    "  print('Playing the Game %d times..........' %(episodes))\n",
    "  \n",
    "  for i in range(episodes):\n",
    "    currstate = 0\n",
    "    \n",
    "    while(currstate!=cells-1):\n",
    "      \n",
    "      prob = random.uniform(0,1)\n",
    "      if(prob>epsilon):\n",
    "        curraction = Q[currstate].index(max(Q[currstate]))\n",
    "      else:\n",
    "        curraction = random.randint(0,num_actions-1)\n",
    "        \n",
    "      reward, nextstate, is_over = env(currstate, curraction)\n",
    "      \n",
    "      Q[currstate][curraction] = Q[currstate][curraction] + alpha * (reward + discount * max(Q[nextstate]) - Q[currstate][curraction])\n",
    "      \n",
    "      if(is_over):\n",
    "        break\n",
    "      currstate = nextstate\n",
    "  \n",
    "  print('Q values for each state-action pair after game play:')\n",
    "  print('            STRAIGHT   LOW JUMP   HIGH JUMP   SLIDE')\n",
    "  for i in range(cells):\n",
    "    rounded_list = Q[i]\n",
    "    for j in range(num_actions):\n",
    "      rounded_list[j] = round(Q[i][j],3)\n",
    "    print('state %d:          %s' %(i,rounded_list))\n",
    "    \n",
    "  print('Policy after self-play starting from 0:')\n",
    "\n",
    "  currstate = 0\n",
    "  while(currstate!=cells-1):\n",
    "    curraction = Q[currstate].index(max(Q[currstate]))\n",
    "    reward, nextstate, is_over = env(currstate, curraction)\n",
    "    print('Current state is %d and immediate reward is %.3f' %(currstate,reward))\n",
    "    if(is_over):\n",
    "      break\n",
    "    currstate = nextstate\n",
    "    \n",
    "  print('Final state is 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nq7qbuyGaBrI",
    "outputId": "1bd0ef6d-1725-4163-c9db-ba836bb3d3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q values before game-play: \n",
      "            STRAIGHT   LOW JUMP   HIGH JUMP   SLIDE\n",
      "state 0:      [0.49707710876286537, 0.060882833306884265, 0.05997944739912564, 0.2889898153020589]\n",
      "state 1:      [0.22831006901659556, 0.9487221279911136, 0.8714656098187759, 0.352629646282798]\n",
      "state 2:      [0.6682953657009333, 0.1877733541290052, 0.5682167679949548, 0.1277812960503455]\n",
      "state 3:      [0.5370295397038074, 0.1406907590459534, 0.322121923465274, 0.6036732999489672]\n",
      "state 4:      [0.09028275999094937, 0.9662621068319686, 0.3752602774623579, 0.30287516115177016]\n",
      "state 5:      [0.19936934856597155, 0.11061428397651318, 0.6813402596159617, 0.7192921923990617]\n",
      "state 6:      [0.8331723648851661, 0.058432012358005325, 0.37189332311703793, 0.7150805209873978]\n",
      "state 7:      [0.5164150860063151, 0.25593213181034324, 0.6267812726470896, 0.9922128671378846]\n",
      "state 8:      [0.3695306340459902, 0.5073918806524085, 0.4891936896916528, 0.4374258868808665]\n",
      "state 9:      [0.21171068691437123, 0.41537226336082833, 0.018199947253572435, 0.6039027391818141]\n",
      "state 10:      [0.7138365685164012, 0.7592522964637595, 0.6529809564699901, 0.6883502997527432]\n",
      "state 11:      [0.6899854742506031, 0.5803793294061457, 0.7501459948839803, 0.2584720183734278]\n",
      "state 12:      [0.39647394767211885, 0.5272340453379997, 0.5587774459720914, 0.1586641872981548]\n",
      "state 13:      [0.42179783073103916, 0.6269371373662943, 0.5929997411061764, 0.06376597614496304]\n",
      "state 14:      [0.670470875915037, 0.4193817097568213, 0.8802111648190277, 0.6371304447621078]\n",
      "state 15:      [0.44478748760560105, 0.7503599683429075, 0.6971174739967183, 0.061907220285676745]\n",
      "state 16:      [0.5867429672979319, 0.36879440668680186, 0.06775887899865674, 0.8409054791359905]\n",
      "state 17:      [0.9235549934114462, 0.6926537106841264, 0.08932157068430624, 0.3752978048272605]\n",
      "state 18:      [0.49759608999407423, 0.3311616367040481, 0.05224707168765563, 0.8427247008368878]\n",
      "state 19:      [0.787982998562353, 0.48611661387460514, 0.8617726646343162, 0.09757862144776341]\n",
      "state 20:      [0, 0, 0, 0]\n",
      "Playing the Game 100000 times..........\n",
      "Q values for each state-action pair after game play:\n",
      "            STRAIGHT   LOW JUMP   HIGH JUMP   SLIDE\n",
      "state 0:          [-0.174, -0.324, -0.324, -0.324]\n",
      "state 1:          [-0.138, -0.288, -0.288, -0.288]\n",
      "state 2:          [-1.048, -0.098, -0.098, -1.048]\n",
      "state 3:          [-0.053, -0.203, -0.203, -0.203]\n",
      "state 4:          [-0.004, -0.154, -0.154, -0.154]\n",
      "state 5:          [0.052, -0.098, -0.098, -0.098]\n",
      "state 6:          [-0.916, 0.034, 0.113, -0.916]\n",
      "state 7:          [0.093, -0.057, -0.057, -0.057]\n",
      "state 8:          [0.159, 0.009, 0.009, 0.009]\n",
      "state 9:          [0.232, 0.082, 0.082, 0.082]\n",
      "state 10:          [-0.325, -0.325, -0.325, 0.313]\n",
      "state 11:          [0.69, 0.58, 0.75, 0.258]\n",
      "state 12:          [0.404, 0.254, 0.254, 0.254]\n",
      "state 13:          [-0.564, 0.386, 0.504, -0.564]\n",
      "state 14:          [0.484, 0.334, 0.334, 0.334]\n",
      "state 15:          [0.593, 0.443, 0.443, 0.443]\n",
      "state 16:          [-0.169, -0.169, -0.169, 0.715]\n",
      "state 17:          [0.924, 0.693, 0.089, 0.375]\n",
      "state 18:          [0.85, 0.7, 0.7, 0.7]\n",
      "state 19:          [1.0, -0.2, -0.2, -0.2]\n",
      "state 20:          [0, 0, 0, 0]\n",
      "Policy after self-play starting from 0:\n",
      "Current state is 0 and immediate reward is -0.050\n",
      "Current state is 1 and immediate reward is -0.050\n",
      "Current state is 2 and immediate reward is -0.050\n",
      "Current state is 3 and immediate reward is -0.050\n",
      "Current state is 4 and immediate reward is -0.050\n",
      "Current state is 5 and immediate reward is -0.050\n",
      "Current state is 6 and immediate reward is -0.030\n",
      "Current state is 8 and immediate reward is -0.050\n",
      "Current state is 9 and immediate reward is -0.050\n",
      "Current state is 10 and immediate reward is -0.050\n",
      "Current state is 12 and immediate reward is -0.050\n",
      "Current state is 13 and immediate reward is -0.030\n",
      "Current state is 15 and immediate reward is -0.050\n",
      "Current state is 16 and immediate reward is -0.050\n",
      "Current state is 18 and immediate reward is -0.050\n",
      "Current state is 19 and immediate reward is 1.000\n",
      "Final state is 20\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\tqlearning()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SonicGame.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
